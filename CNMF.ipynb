{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a two-photon Calcium Imaging dataset. The demo shows how to construct the `params`, `MotionCorrect` and `cnmf` objects and call the relevant functions. You can also run a large part of the pipeline with a single method (`cnmf.fit_file`). See inside for details.\n",
    "\n",
    "Dataset couresy of Sue Ann Koay and David Tank (Princeton University)\n",
    "\n",
    "This demo pertains to two photon data. For a complete analysis pipeline for one photon microendoscopic data see demo_pipeline_cnmfE.ipynb</span></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in the companion paper. </span></p>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.150474Z",
     "start_time": "2021-09-07T09:12:40.864487Z"
    }
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bpl\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.animation as animation\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logger (optional)\n",
    "You can log to a file using the filename parameter, or make the output more or less verbose by setting level to `logging.DEBUG`, `logging.INFO`, `logging.WARNING`, or `logging.ERROR`. A filename argument can also be passed to store the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.168488Z",
     "start_time": "2021-09-07T09:12:43.151514Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select file(s) to be processed\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file(s). Remember to pass the `fname` variable as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.189434Z",
     "start_time": "2021-09-07T09:12:43.169282Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = '/media/david/hdd1/David_GCAMP/20210827'\n",
    "filename = 'file_00001_1'\n",
    "fnames = [directory+'/sliced_data/'+filename+'.tif' ]\n",
    "#fnames\n",
    "#fnames = ['file_00011_cai1.tif']  # filename to be processed\n",
    "#if fnames[0] in ['Sue_2x_3000_40_-46.tif', 'demoMovie.tif','file_00011_cai1.tif']:\n",
    "#    fnames = [download_demo(fnames[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.210442Z",
     "start_time": "2021-09-07T09:12:43.190644Z"
    }
   },
   "outputs": [],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.229303Z",
     "start_time": "2021-09-07T09:12:43.211194Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read tag file\n",
    "dict_name = directory+'/tag/'+filename[:-2]+'.json'\n",
    "with open(dict_name, 'r') as f:\n",
    "    tag = json.load(f)\n",
    "length = tag['length']\n",
    "scanZoomFactor = tag['scanZoomFactor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the movie (optional)\n",
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. Press `q` to close the video panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "We set some parameters that are relevant to the file, and then parameters for motion correction, processing with CNMF and component quality evaluation. Note that the dataset `Sue_2x_3000_40_-46.tif` has been spatially downsampled by a factor of 2 and has a lower than usual spatial resolution (2um/pixel). As a result several parameters (`gSig, strides, max_shifts, rf, stride_cnmf`) have lower values (halved compared to a dataset with spatial resolution 1um/pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.248665Z",
     "start_time": "2021-09-07T09:12:43.230064Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 30                             # imaging rate in frames per second\n",
    "decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = (96, 96)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (32, 32)         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = (12,12)          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "#p = 0 turns deconvolution off \n",
    "#If transients in your data rise instantaneously, set p = 1 (occurs at low sample rate or slow indicator). \n",
    "#If transients have visible rise time, set p = 2.\n",
    "gnb = 2                     # number of global background components. This is a measure of the complexity of your background noise.\n",
    "merge_thr = 0.7             # merging threshold, max correlation allowed\n",
    "#Merging threshold of components after initialization. If two components are correlated more than this value, they are merged and treated as one.\n",
    "rf = 50                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "#Should be at least 3 to 4 times larger than the expected neuron size to capture the complete neuron and its local background.\n",
    "stride_cnmf = 30             # amount of overlap between the patches in pixels\n",
    "#This should be roughly the neuron diameter. Larger overlap increases computational load, but yields better results during reconstruction/denoising of the data.\n",
    "K = 4                       # Number of (expected) components per patch.\n",
    "gSig = [16, 16]               # expected half size of neurons in pixels, CRUCIAL parameter for proper component detection.\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "#Defaults to 1 (no compression). Can be set to 2 or even higher to save resources, but might impair quality.\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2               # signal to noise ratio for accepting a component\n",
    "#Peak SNR is calculated from strong calcium transients and the noise estimate.\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
    "#CNN-based classifier (cnn): The shape of components is evaluated by a 4-layered convolutional neural network trained on a manually annotated dataset. \n",
    "#The CNN assigns a value of 0-1 to each component depending on its resemblance to a neuronal soma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a parameters object\n",
    "You can creating a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values. The resulting `params` object is a collection of subdictionaries pertaining to the dataset to be analyzed `(params.data)`, motion correction `(params.motion)`, data pre-processing `(params.preprocess)`, initialization `(params.init)`, patch processing `(params.patch)`, spatial and temporal component `(params.spatial), (params.temporal)`, quality evaluation `(params.quality)` and online processing `(params.online)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.293872Z",
     "start_time": "2021-09-07T09:12:43.249900Z"
    }
   },
   "outputs": [],
   "source": [
    "opts_dict = {'fnames': fnames,\n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)#Parameter object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a cluster\n",
    "To enable parallel processing a (local) cluster needs to be set up. This is done with a cell below. The variable `backend` determines the type of cluster used. The default value `'local'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/master/CLUSTER.md). The resulting variable `dview` expresses the cluster option. If you use `dview=dview` in the downstream analysis then parallel processing will be used. If you use `dview=None` then no parallel processing will be employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory mapping \n",
    "\n",
    "The cell below memory maps the file in order `'C'` and then loads the new memory mapped file. The saved files from motion correction are memory mapped files stored in `'F'` order. Their paths are stored in `mc.mmap_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.320775Z",
     "start_time": "2021-09-07T09:12:43.294687Z"
    }
   },
   "outputs": [],
   "source": [
    "fname_new = [directory+'/sliced_data/'+filename+'_memmap__d1_512_d2_512_d3_1_order_C_frames_'+str(length)+'_.mmap' ]\n",
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new[0])\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    #load frames in python format (T x X x Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:12:43.434198Z",
     "start_time": "2021-09-07T09:12:43.321752Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF on patches in parallel\n",
    "\n",
    "- The FOV is split is different overlapping patches that are subsequently processed in parallel by the CNMF algorithm.\n",
    "- The results from all the patches are merged with special attention to idendtified components on the border.\n",
    "- The results are then refined by additional CNMF iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:10.864680Z",
     "start_time": "2021-09-07T09:12:43.435410Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RUN CNMF ON PATCHES\n",
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0). If you want to have\n",
    "# deconvolution within each patch change params.patch['p_patch'] to a\n",
    "# nonzero value\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the results\n",
    "Briefly inspect the results by plotting contours of identified components against correlation image.\n",
    "The results of the algorithm are stored in the object `cnm.estimates`. More information can be found in the definition of the `estimates` object and in the [wiki](https://github.com/flatironinstitute/CaImAn/wiki/Interpreting-Results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:15.537205Z",
     "start_time": "2021-09-07T09:14:10.865427Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run (seeded) CNMF  on the full Field of View  \n",
    "You can re-run the CNMF algorithm seeded on just the selected components from the previous step. Be careful, because components rejected on the previous step will not be recovered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:29.155886Z",
     "start_time": "2021-09-07T09:14:15.537882Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "cnm2 = cnm.refit(images, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:29.683301Z",
     "start_time": "2021-09-07T09:14:29.156638Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:29.992306Z",
     "start_time": "2021-09-07T09:14:29.684163Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components)\n",
    "idx = cnm2.estimates.idx_components\n",
    "empty_image = np.zeros((Cn.shape[0],Cn.shape[1]))\n",
    "coor_g = [cnm2.estimates.coordinates[cr] for cr in idx]\n",
    "#a = cm.utils.visualization.plot_only_contours(cnm2.estimates.A[:,idx],empty_image,coordinates=coor_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:30.414688Z",
     "start_time": "2021-09-07T09:14:29.993288Z"
    }
   },
   "outputs": [],
   "source": [
    "cnm2.estimates.plot_only_accept(img=Cn, idx=cnm2.estimates.idx_components,display_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:15:02.300960Z",
     "start_time": "2021-09-07T09:15:02.270088Z"
    }
   },
   "outputs": [],
   "source": [
    "#cnm2.estimates.plot_only_reject(img=Cn, idx=cnm2.estimates.idx_components,display_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:31.654999Z",
     "start_time": "2021-09-07T09:14:30.434398Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "print('Origial component is ')\n",
    "print(cnm2.estimates.idx_components)\n",
    "cnm2.estimates.threshold_spatial_components()\n",
    "A_thr = cnm2.estimates.A_thr\n",
    "A_gt_thr_bin = A_thr.toarray() > 0\n",
    "size_neurons_gt = A_gt_thr_bin.sum(0)\n",
    "print('The size of spatial component is ')\n",
    "print(np.sort(size_neurons_gt[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:31.724549Z",
     "start_time": "2021-09-07T09:14:31.655799Z"
    }
   },
   "outputs": [],
   "source": [
    "min_size = 200\n",
    "max_size = 2000\n",
    "remove_small = 1\n",
    "if remove_small:\n",
    "    cnm2.estimates.remove_small_large_neurons(min_size,max_size)\n",
    "print('After remove small and large')\n",
    "print(cnm2.estimates.idx_components)\n",
    "components_to_keep = cnm2.estimates.idx_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.125338Z",
     "start_time": "2021-09-07T09:14:31.725249Z"
    }
   },
   "outputs": [],
   "source": [
    "cnm2.estimates.plot_only_accept(img=Cn, idx=cnm2.estimates.idx_components,display_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.145399Z",
     "start_time": "2021-09-07T09:14:32.126127Z"
    }
   },
   "outputs": [],
   "source": [
    "components_to_delete = [4,10]\n",
    "components_to_delete = np.array(components_to_delete)-1\n",
    "components_to_keep = np.delete(components_to_keep,components_to_delete)\n",
    "cnm2.estimates.idx_components = np.intersect1d(cnm2.estimates.idx_components, components_to_keep)\n",
    "cnm2.estimates.idx_components_bad = np.setdiff1d(np.arange(cnm2.estimates.A.shape[-1]), cnm2.estimates.idx_components)\n",
    "print('After delete manually')\n",
    "print(cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.550316Z",
     "start_time": "2021-09-07T09:14:32.146076Z"
    }
   },
   "outputs": [],
   "source": [
    "cnm2.estimates.plot_only_accept(img=Cn, idx=cnm2.estimates.idx_components,display_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.677440Z",
     "start_time": "2021-09-07T09:14:32.552445Z"
    }
   },
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.696337Z",
     "start_time": "2021-09-07T09:14:32.678233Z"
    }
   },
   "outputs": [],
   "source": [
    "# rejected components\n",
    "plot_reject = 0\n",
    "if plot_reject:\n",
    "    if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "        cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "    else:\n",
    "        print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only high quality components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.715927Z",
     "start_time": "2021-09-07T09:14:32.697201Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = cnm2.estimates.idx_components\n",
    "cnm2.estimates.select_components(use_object=True)\n",
    "cnm2.estimates.idx_components = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:32.839966Z",
     "start_time": "2021-09-07T09:14:32.716619Z"
    }
   },
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing, saving, and creating denoised version\n",
    "### You can save an hdf5 file with all the fields of the cnmf object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:33.010612Z",
     "start_time": "2021-09-07T09:14:32.840700Z"
    }
   },
   "outputs": [],
   "source": [
    "save_results = 1\n",
    "if save_results:\n",
    "    if not os.path.isdir(directory+'/preprocess'):\n",
    "        os.mkdir(directory+'/preprocess')\n",
    "    if os.path.isfile(directory+'/preprocess/'+filename+'.hdf5'):\n",
    "        os.remove(directory+'/preprocess/'+filename+'.hdf5')\n",
    "    cnm2.save(directory+'/preprocess/'+filename+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:54.405841Z",
     "start_time": "2021-09-07T09:14:33.011444Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "                    cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])\n",
    "if not os.path.isdir(directory+'/denoise'):\n",
    "    os.mkdir(directory+'/denoise')\n",
    "np.save(directory+'/denoise/'+'denoise_'+filename,denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:54.446330Z",
     "start_time": "2021-09-07T09:14:54.427277Z"
    }
   },
   "outputs": [],
   "source": [
    "save_movie = 0\n",
    "coor_g = [cnm2.estimates.coordinates[cr] for cr in range(len(idx))]\n",
    "if save_movie:\n",
    "    # Use Agg backend for canvas\n",
    "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(directory+'/movie/ROI_'+filename+'.avi', fourcc, 30.0, (432,288),0)\n",
    "    # loop over your images\n",
    "    for i in range(length):\n",
    "        fig = plt.figure(1)\n",
    "        img = denoised[i,:,:]\n",
    "        #img = cv2.normalize(denoised[i,:,:].reshape(denoised.shape[2],denoised.shape[1]), None, 0, 255, cv2.NORM_MINMAX)\n",
    "        plt.imshow(img,cmap=plt.cm.Greys_r)\n",
    "        for c in coor_g:\n",
    "            v = c['coordinates']\n",
    "            plt.plot(*v.T,c='w')\n",
    "        # put pixel buffer in numpy array\n",
    "        canvas = FigureCanvas(fig)\n",
    "        plt.close(1)\n",
    "        canvas.draw()\n",
    "        mat = np.array(canvas.renderer._renderer)\n",
    "        mat = cv2.cvtColor(mat, cv2.COLOR_RGB2GRAY)\n",
    "        # write frame to video\n",
    "        out.write(mat)\n",
    "    # close video writer\n",
    "    #cv2.destroyAllWindows()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T09:14:54.511064Z",
     "start_time": "2021-09-07T09:14:54.447020Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
